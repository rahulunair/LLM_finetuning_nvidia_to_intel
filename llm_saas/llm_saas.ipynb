{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fee054d-cb09-4905-b568-d267559bc8e5",
   "metadata": {},
   "source": [
    "## Effortless GenAI Integration with PredictionGuard LLM APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705cbe5-eece-42d4-8a90-e2fa691b0050",
   "metadata": {},
   "source": [
    "This notebook serves as a practical demonstration of how PredictionGuard, an LLM API services startup, simplifies the integration of advanced GenAI capabilities into SaaS applications.\n",
    "<br></br>\n",
    "PredictionGuard is deployed on the Intel Developer Cloud and uses Intel Gaudi 2 servers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa5ea9d-9003-4699-909f-723dd7ada5bd",
   "metadata": {},
   "source": [
    "**Install predictionguard python package:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefcf9bc-aab0-4f51-a0bd-ac5158106815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q -U predictionguard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599e8bd-b82e-4d88-b679-517c9ce7c6de",
   "metadata": {},
   "source": [
    "**Import Required Packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2c939-869c-42d4-957f-2e1af25d6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import predictionguard as pg\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005022e1-05db-4c70-aa36-6bbdf6d58b1e",
   "metadata": {},
   "source": [
    "This cell imports the necessary libraries: os for environment variable management, predictionguard as the library for interfacing with PredictionGuard, and getpass for secure token input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039dec7f-2359-4689-8c70-f7881e394e57",
   "metadata": {},
   "source": [
    "**Setting up PredictionGuard Access Token:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796cbe8-7bdc-4d73-93ac-9aa73021f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_token = getpass('Enter your Prediction Guard access token: ')\n",
    "os.environ['PREDICTIONGUARD_TOKEN'] = get_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8637f0c-1fb2-49db-93af-c43a03cd2d3d",
   "metadata": {},
   "source": [
    "**List Availble Models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968c510-eee9-4424-a87d-d8657b7dfc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.Chat.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5611c884-a405-47d7-91b1-efecd4db6443",
   "metadata": {},
   "source": [
    "**Creating a Chat Session:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2237fc2-f6ba-4b46-85fe-b040a958a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that provide clever and sometimes funny responses.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Tell me a funny story\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Well, technically vertically out from the center of the earth.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Haha. Good one.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "result = pg.Chat.create(\n",
    "    model=\"Neural-Chat-7B\",\n",
    "    #model=\"Notus-7B\",\n",
    "    #model=\"Zephyr-7B-Beta\",\n",
    "    messages=messages\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f451b-3441-48f8-9a41-8d3e59e214fc",
   "metadata": {},
   "source": [
    "The above cell defines a chat history and uses PredictionGuard's Chat.create() method to interact with a specified chat model. The script then prints the response from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c392979b-a9f6-42a4-af51-f4e9d7ae43e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382bed1-f9a9-455e-a830-cfc0dd9eeb08",
   "metadata": {},
   "source": [
    "**A simple chatbot under 20 lines of code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0595306-4963-400a-bc3b-613b39bd1ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Welcome to the Prediction Guard Chatbot! Let me know how can I help you\\n\")\n",
    "\n",
    "chat_history = []\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() == \"stop\" or user_input.lower() == \"bye\":\n",
    "        print(\"Bot: Bye!\")\n",
    "        break\n",
    "    else:\n",
    "        chat_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        })\n",
    "        bot_response = pg.Chat.create(model=\"Neural-Chat-7B\", messages=chat_history\n",
    "        )[\"choices\"][0][\"message\"][\"content\"].split(\"\\n\")[0].strip()\n",
    "        chat_history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": bot_response\n",
    "        })\n",
    "        print(\"Bot: \", bot_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ea78d-7056-4039-9112-b3159ded98dc",
   "metadata": {},
   "source": [
    "More details about prediction Guard APIs can be obtained [here](https://docs.predictionguard.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efbb3a-e348-4f7b-9128-fcdbdd59d453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
